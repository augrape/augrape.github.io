<!DOCTYPE html>
<html lang="en">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="Scrapy源码分析之Scheduler"/>




  <meta name="keywords" content="Scrapy,源码篇,去重," />





  <link rel="alternate" href="/default" title="Just Write.">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="http://yoursite.com/2019/12/12/Scrapy源码分析之Scheduler/"/>


<meta name="description" content="我所理解的Scrapy去重模块。直接上源码。">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy源码分析之Scheduler">
<meta property="og:url" content="http://yoursite.com/2019/12/12/Scrapy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BScheduler/index.html">
<meta property="og:site_name" content="Just Write.">
<meta property="og:description" content="我所理解的Scrapy去重模块。直接上源码。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-12-12T15:44:03.000Z">
<meta property="article:modified_time" content="2020-08-14T06:42:09.175Z">
<meta property="article:author" content="Pengfeix">
<meta property="article:tag" content="Scrapy">
<meta property="article:tag" content="源码篇">
<meta property="article:tag" content="去重">
<meta name="twitter:card" content="summary">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> Scrapy源码分析之Scheduler - Just Write. </title>
  <meta name="generator" content="Hexo 4.2.1"></head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Just Write.</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Scrapy源码分析之Scheduler
        
      </h1>

      <time class="post-time">
          Dec 12 2019
      </time>
    </header>



    
            <div class="post-content">
            <p>我所理解的Scrapy去重模块。<br>直接上源码。</p>
<a id="more"></a>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># site-packages/scrapy/core/scheduler.py</span></span><br><span class="line"><span class="comment"># scheduler对象通过类的from_cralwer函数生成的。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scheduler</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dupefilter, jobdir=None, dqclass=None, mqclass=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 logunser=False, stats=None, pqclass=None, crawler=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :dupefilter parameter: 去重模块</span></span><br><span class="line"><span class="string">        :dqclass parameter: 磁盘队列 LIFI磁盘队列,主要任务是停止爬虫后,再次启动完成续接任务</span></span><br><span class="line"><span class="string">        :mqclass parameter: 内存队列 因为pqclass而存在的</span></span><br><span class="line"><span class="string">        :pqclass parameter: 带优先级队列, 使用第三方queuelib, 对request请求按优先级进行排序</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.df = dupefilter</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        dupefilter = create_instance()</span><br><span class="line">        <span class="keyword">return</span> cls(dupefilter, pqclass, dqclass, mqclass)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request.dont_filter <span class="keyword">and</span> self.df.request_seen(request):</span><br><span class="line">            self.df.log(request, self.spider)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># scrapy/dupefilters.py</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RFPDupeFilter</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.fingerprints = set()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request_seen</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        fp = self.request_fingerprint(request)</span><br><span class="line">        <span class="keyword">if</span> fp <span class="keyword">in</span> self.fingerprints:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        self.fingerprints.add(fp)</span><br><span class="line">        <span class="keyword">if</span> self.file:</span><br><span class="line">            self.file.write(fp + <span class="string">'\n'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request_fingerprint</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> request_fingerprint(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># scrapy/utils/request.py</span></span><br><span class="line"><span class="keyword">import</span> weakref</span><br><span class="line"></span><br><span class="line">_fingerprint_cache = weakref.WeakKeyDictionary()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_fingerprint</span><span class="params">(request, include_headers=None, keep_fragments=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    to_bytes(request.method)</span></span><br><span class="line"><span class="string">        计算指纹时，请求方法(如GET、POST)被计算在内</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    canonicalize_url()</span></span><br><span class="line"><span class="string">        将url规范化的方法</span></span><br><span class="line"><span class="string">        http://www.example.com/query?id=111&amp;cat=222</span></span><br><span class="line"><span class="string">        http://www.example.com/query?cat=222&amp;id=111</span></span><br><span class="line"><span class="string">        这样参数位置变化，但参数值不变的网址，表示的仍是同一个网址，符合现实逻辑。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    request.body的属性是字符串：</span></span><br><span class="line"><span class="string">        一般GET方法的body为空字符串，不考虑；</span></span><br><span class="line"><span class="string">        而POST方法要上传kwages（类型是dict），</span></span><br><span class="line"><span class="string">        要经过urllib.parse.urlencode()函数转换后才能变成request.body</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    加密</span></span><br><span class="line"><span class="string">        fp = hashlib.sha1() 安全哈希算法 基于MD5 加密后长度更长 比MD5多32位 也更安全但速度较慢</span></span><br><span class="line"><span class="string">    写入内存中</span></span><br><span class="line"><span class="string">        cache[include_headers] = fp.hexdigest()</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> include_headers:</span><br><span class="line">        include_headers = tuple(to_bytes(h.lower())</span><br><span class="line">                                 <span class="keyword">for</span> h <span class="keyword">in</span> sorted(include_headers))</span><br><span class="line">    cache = _fingerprint_cache.setdefault(request, &#123;&#125;)</span><br><span class="line">    cache_key = (include_headers, keep_fragments)</span><br><span class="line">    <span class="keyword">if</span> cache_key <span class="keyword">not</span> <span class="keyword">in</span> cache:</span><br><span class="line">        fp = hashlib.sha1()</span><br><span class="line">        fp.update(to_bytes(request.method))</span><br><span class="line">        fp.update(to_bytes(canonicalize_url(request.url, keep_fragments=keep_fragments)))</span><br><span class="line">        fp.update(request.body <span class="keyword">or</span> <span class="string">b''</span>)</span><br><span class="line">        <span class="keyword">if</span> include_headers:</span><br><span class="line">            <span class="keyword">for</span> hdr <span class="keyword">in</span> include_headers:</span><br><span class="line">                <span class="keyword">if</span> hdr <span class="keyword">in</span> request.headers:</span><br><span class="line">                    fp.update(hdr)</span><br><span class="line">                    <span class="keyword">for</span> v <span class="keyword">in</span> request.headers.getlist(hdr):</span><br><span class="line">                        fp.update(v)</span><br><span class="line">        cache[cache_key] = fp.hexdigest()</span><br><span class="line">    <span class="keyword">return</span> cache[cache_key]</span><br></pre></td></tr></table></figure>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/Scrapy/">Scrapy</a>
		  
			<a href="/tags/%E6%BA%90%E7%A0%81%E7%AF%87/">源码篇</a>
		  
			<a href="/tags/%E5%8E%BB%E9%87%8D/">去重</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2020/08/14/%E6%80%8E%E6%A0%B7%E8%B5%B7%E4%B8%80%E4%B8%AA%E5%B7%A7%E5%A6%99%E7%9A%84%E6%A0%87%E9%A2%98%E5%91%A2/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">怎样起一个巧妙的标题呢</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2019/12/10/RabbitMQ%E5%BF%85%E6%87%82%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98/">
        <span class="next-text nav-default">RabbitMQ必懂的几个问题</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2020
    <span class="footer-author">Pengfeix.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> and <a class="theme-link" href="https://github.com/frostfan/hexo-theme-polarbear" target="_blank" rel="noopener">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
