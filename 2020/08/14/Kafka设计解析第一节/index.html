<!DOCTYPE html>
<html lang="en">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="Kafka设计解析第一节"/>




  <meta name="keywords" content="Kafka," />





  <link rel="alternate" href="/default" title="Just Write.">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="http://yoursite.com/2020/08/14/Kafka设计解析第一节/"/>


<meta name="description" content="使用消息系统的优势。并介绍了Kafka的架构，Producer消息路由，Consumer Group以及由其实现的不同消息分发方式，Topic &amp; Partition，最后介绍了Kafka Consumer为何使用pull模式以及Kafka提供的三种delivery guarantee。">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka设计解析第一节">
<meta property="og:url" content="http://yoursite.com/2020/08/14/Kafka%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%E7%AC%AC%E4%B8%80%E8%8A%82/index.html">
<meta property="og:site_name" content="Just Write.">
<meta property="og:description" content="使用消息系统的优势。并介绍了Kafka的架构，Producer消息路由，Consumer Group以及由其实现的不同消息分发方式，Topic &amp; Partition，最后介绍了Kafka Consumer为何使用pull模式以及Kafka提供的三种delivery guarantee。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-08-14T10:09:31.000Z">
<meta property="article:modified_time" content="2020-08-17T08:47:41.548Z">
<meta property="article:author" content="Pengfeix">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> Kafka设计解析第一节 - Just Write. </title>
  <meta name="generator" content="Hexo 4.2.1"></head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Just Write.</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Kafka设计解析第一节
        
      </h1>

      <time class="post-time">
          Aug 14 2020
      </time>
    </header>



    
            <div class="post-content">
            <p>  使用消息系统的优势。并介绍了Kafka的架构，Producer消息路由，Consumer Group以及由其实现的不同消息分发方式，Topic &amp; Partition，最后介绍了Kafka Consumer为何使用pull模式以及Kafka提供的三种delivery guarantee。</p>
<a id="more"></a>

<h4 id="Kafka创建背景"><a href="#Kafka创建背景" class="headerlink" title="Kafka创建背景"></a>Kafka创建背景</h4><p>  &thinsp;&thinsp;Kafka是一个消息系统，原本开发自LinkedIn，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。</p>
<p>  &emsp;&emsp;活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。 </p>
<h4 id="Kafka介绍"><a href="#Kafka介绍" class="headerlink" title="Kafka介绍"></a>Kafka介绍</h4><p>Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下 ：</p>
<ul>
<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输</li>
<li>同时支持离线数据处理和实时数据处理</li>
<li>Scale out：支持在线水平扩展</li>
</ul>
<h4 id="使用消息系统目的在哪"><a href="#使用消息系统目的在哪" class="headerlink" title="使用消息系统目的在哪"></a>使用消息系统目的在哪</h4><ul>
<li>解耦<ul>
<li>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</li>
</ul>
</li>
<li>冗余<ul>
<li>有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</li>
</ul>
</li>
<li>扩展性<ul>
<li>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</li>
</ul>
</li>
<li>灵活性&amp;峰值处理能力<ul>
<li>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</li>
</ul>
</li>
<li>可恢复性<ul>
<li>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</li>
</ul>
</li>
<li>顺序保证<ul>
<li>在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。</li>
</ul>
</li>
<li>缓冲<ul>
<li>在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</li>
</ul>
</li>
<li>异步通信<ul>
<li>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</li>
</ul>
</li>
</ul>
<h4 id="Kafka架构"><a href="#Kafka架构" class="headerlink" title="Kafka架构"></a>Kafka架构</h4><p>Terminology<br>| 名称        | 解释   |<br>| :——–:   | :—–:  |<br>| Borker     | 消息中间件处理节点，一个Kafka节点就是一个broker，一个或多个Broker就可以组成一个Kafka集群|<br>| Topic        |   Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic   |<br>| Producer        |    消息生产者，向Broker发送消息的客户端    |<br>| Consumer        |    消息消费者，从Broker读取消息的客户端    |<br>| ConsumerGroup| 每个Consumer属于一个特定的ConsumerGroup，一条消息可以发送到多个不同的ConsumerGroup，但是一个ConsumerGroup中只能有一个Consumer能够消费该信息|<br>|Partition|物理上的概念，一个topic可以分为多个partition，每个partition内部是有序的|</p>
<ul>
<li><p>Borker</p>
<ul>
<li>Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>
</ul>
</li>
<li><p>Topic</p>
<ul>
<li>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</li>
</ul>
</li>
<li><p>Partition</p>
<ul>
<li>Parition是物理上的概念，每个Topic包含一个或多个Partition.</li>
</ul>
</li>
<li><p>Producer</p>
<ul>
<li>负责发布消息到Kafka broker</li>
</ul>
</li>
<li><p>Consumer</p>
<ul>
<li>消息消费者，向Kafka broker读取消息的客户端。</li>
</ul>
</li>
<li><p>Consumer Group</p>
<ul>
<li>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>
</ul>
</li>
<li><p>Topic &amp; Partition</p>
<p>&emsp;&emsp;Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应会生成共32个文件夹</p>
<p>&emsp;&emsp;每个日志文件都是一个log entry序列，每个log entry包含一个4字节整型数值（值为N+5），1个字节的”magic value”，4个字节的CRC校验码，其后跟N个字节的消息体。每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>message length</th>
<th align="right">4 bytes (value: 1+4+n)</th>
</tr>
</thead>
<tbody><tr>
<td>“magic” value</td>
<td align="right">1 byte</td>
</tr>
<tr>
<td>crc</td>
<td align="right">4 bytes</td>
</tr>
<tr>
<td>payload</td>
<td align="right">n bytes</td>
</tr>
</tbody></table>
<p>  &emsp;&emsp;这个log entry并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以“.kafka”为后缀。另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围，</p>
<p>  &emsp;&emsp;因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>
<p>  &emsp;&emsp;对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The minimum age of a <span class="built_in">log</span> file to be eligible <span class="keyword">for</span> deletion</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="meta">#</span><span class="bash"> The maximum size of a <span class="built_in">log</span> segment file. When this size is reached a new <span class="built_in">log</span> segment will be created.</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"><span class="meta">#</span><span class="bash"> The interval at <span class="built_in">which</span> <span class="built_in">log</span> segments are checked to see <span class="keyword">if</span> they can be deleted according to the retention policies</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta">#</span><span class="bash"> If log.cleaner.enable=<span class="literal">true</span> is <span class="built_in">set</span> the cleaner will be enabled and individual logs can <span class="keyword">then</span> be marked <span class="keyword">for</span> <span class="built_in">log</span> compaction.</span></span><br><span class="line">log.cleaner.enable=false</span><br></pre></td></tr></table></figure>

<p>  &emsp;&emsp;这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。</p>
<h4 id="Producer消息路由"><a href="#Producer消息路由" class="headerlink" title="Producer消息路由"></a>Producer消息路由</h4><p>  &emsp;&emsp;Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。可以在$KAFKA_HOME/config/server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。<br>  &emsp;&emsp;在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的paritition. class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。本例中如果key可以被解析为整数则将对应的整数与Partition总数取余，该消息会被发送到该数对应的Partition。（每个Parition都会有个序号,序号从0开始）</p>
<p>  &emsp;&emsp;则key相同的消息会被发送并存储到同一个partition里，而且key的序号正好和Partition序号相同。</p>
<h4 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h4><p>&emsp;&emsp;(本节所有描述都是基于Consumer hight level API而非low level API)。</p>
<p>&emsp;&emsp;使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。</p>
<p>&emsp;&emsp;这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。</p>
<p>&emsp;&emsp;实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。</p>
<h4 id="Kafka-delivery-guarantee"><a href="#Kafka-delivery-guarantee" class="headerlink" title="Kafka delivery guarantee"></a>Kafka delivery guarantee</h4><ul>
<li><code>At most one</code>消息可能会丢，但绝不会重复传输</li>
<li><code>At least one</code>消息不会丢失，但可能会重复传输</li>
<li><code>Exactly once</code>每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。</li>
</ul>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/Kafka/">Kafka</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/2019/12/12/Scrapy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BScheduler/">
        <span class="next-text nav-default">Scrapy源码分析之Scheduler</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2020
    <span class="footer-author">Pengfeix.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> and <a class="theme-link" href="https://github.com/frostfan/hexo-theme-polarbear" target="_blank" rel="noopener">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
